{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n",
    "from PIL import Image\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_name = \"../../data/ade20k.jpeg\"\n",
    "image_name = \"../../data/cats.jpg\"\n",
    "image_name = \"../../data/penguins.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image if the file exists, else read from url.\n",
    "if os.path.exists(image_name):\n",
    "  image = Image.open(image_name)\n",
    "else:\n",
    "  url = \"https://huggingface.co/datasets/shi-labs/oneformer_demo/resolve/main/ade20k.jpeg\"\n",
    "  response = requests.get(url, stream=True)\n",
    "  response.raise_for_status()  # Check for HTTP errors\n",
    "  image = Image.open(response.raw)\n",
    "  # save the image\n",
    "  with open(image_name, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"shi-labs/oneformer_coco_swin_large\"\n",
    "task_type = \"panoptic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = OneFormerProcessor.from_pretrained(\n",
    "model_name\n",
    ")  # Load once here\n",
    "model = OneFormerForUniversalSegmentation.from_pretrained(\n",
    "model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, task_inputs=[\n",
    "                    task_type], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"outputs.keys()=\", outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_type == \"semantic\":\n",
    "    predicted_map = processor.post_process_semantic_segmentation(\n",
    "        outputs, target_sizes=[image.size[::-1]])[0]\n",
    "elif task_type == \"panoptic\":\n",
    "    prediction = processor.post_process_panoptic_segmentation(\n",
    "        outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    predicted_map = prediction[\"segmentation\"]\n",
    "    segments_info = prediction[\"segments_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predicted_map.shape=\", predicted_map.shape)\n",
    "print(f\"predicted_map.unique()=\", predicted_map.unique())\n",
    "if task_type == \"panoptic\":\n",
    "  print(f\"segments_info=\", segments_info)\n",
    "  print(f\"prediction.keys()=\", prediction.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_map)\n",
    "plt.title(task_type + \"Segmentation\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.savefig(\"../../result/oneformer_segm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
